{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenizer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywm7TR4MxDpN",
        "outputId": "5a0b3e63-1e52-41a0-9727-d98da7c8f94b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "sentences = [\n",
        "    'i love my dog',\n",
        "    'I, love my cat',\n",
        "    'You love my dog!',\n",
        "    'The-world was ended ! @ # & * 1 , ซับ'\n",
        "]\n",
        "\n",
        "test_sentences = [\n",
        "    'i really love my dog',\n",
        "    'my dog loves my manatee'\n",
        "]\n",
        "\n",
        "num_words = 100\n",
        "tokenizer = Tokenizer(num_words = num_words + 1)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_counts = tokenizer.word_counts\n",
        "word_docs = tokenizer.word_docs\n",
        "word_index = tokenizer.word_index\n",
        "document_count = tokenizer.document_count\n",
        "sequences = tokenizer.texts_to_sequences(test_sentences)\n",
        "\n",
        "print(word_counts, '\\n') # แสดงความถี่ของคำ\n",
        "print(word_docs, '\\n') # มีในกี่ doc\n",
        "print(word_index, '\\n') # อันดับของคำ เรียงตามความถี่\n",
        "print(document_count, '\\n') # จำนวน doc\n",
        "\n",
        "print(sequences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('i', 2), ('love', 3), ('my', 3), ('dog', 2), ('cat', 1), ('you', 1), ('the', 1), ('world', 1), ('was', 1), ('ended', 1), ('1', 1), ('ซับ', 1)]) \n",
            "\n",
            "defaultdict(<class 'int'>, {'dog': 2, 'i': 2, 'my': 3, 'love': 3, 'cat': 1, 'you': 1, '1': 1, 'world': 1, 'the': 1, 'was': 1, 'ซับ': 1, 'ended': 1}) \n",
            "\n",
            "{'love': 1, 'my': 2, 'i': 3, 'dog': 4, 'cat': 5, 'you': 6, 'the': 7, 'world': 8, 'was': 9, 'ended': 10, '1': 11, 'ซับ': 12} \n",
            "\n",
            "4 \n",
            "\n",
            "[[3, 1, 2, 4], [2, 4, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhexUDWvxSJR",
        "outputId": "cec4391d-4271-4675-a969-de88b97db077",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "padded = pad_sequences(sequences, maxlen=10, padding=\"pre\", truncating=\"post\") # default\n",
        "print('padding pre \\n',padded, '\\n')\n",
        "\n",
        "padded = pad_sequences(sequences, maxlen=10, padding=\"post\", truncating=\"post\")\n",
        "print('padding post \\n',padded, '\\n')\n",
        "\n",
        "padded = pad_sequences(sequences, maxlen=2, padding=\"pre\", truncating=\"post\") # default\n",
        "print('truncating post \\n',padded, '\\n')\n",
        "\n",
        "padded = pad_sequences(sequences, maxlen=2, padding=\"pre\", truncating=\"pre\") \n",
        "print('truncating pre \\n',padded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "padding pre \n",
            " [[0 0 0 0 0 0 3 1 2 4]\n",
            " [0 0 0 0 0 0 0 2 4 2]] \n",
            "\n",
            "padding post \n",
            " [[3 1 2 4 0 0 0 0 0 0]\n",
            " [2 4 2 0 0 0 0 0 0 0]] \n",
            "\n",
            "truncating post \n",
            " [[3 1]\n",
            " [2 4]] \n",
            "\n",
            "truncating pre \n",
            " [[2 4]\n",
            " [4 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjQhbuiJG6df"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}